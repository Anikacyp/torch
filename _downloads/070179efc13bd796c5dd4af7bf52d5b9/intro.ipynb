{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mYq1KkvkUFq8"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://docs.pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fksOOjbwUFq_"
      },
      "source": [
        "**Learn the Basics** \\|\\| [Quickstart](quickstart_tutorial.html) \\|\\|\n",
        "[Tensors](tensorqs_tutorial.html) \\|\\| [Datasets &\n",
        "DataLoaders](data_tutorial.html) \\|\\|\n",
        "[Transforms](transforms_tutorial.html) \\|\\| [Build\n",
        "Model](buildmodel_tutorial.html) \\|\\|\n",
        "[Autograd](autogradqs_tutorial.html) \\|\\|\n",
        "[Optimization](optimization_tutorial.html) \\|\\| [Save & Load\n",
        "Model](saveloadrun_tutorial.html)\n",
        "\n",
        "Learn the Basics\n",
        "================\n",
        "\n",
        "Authors: [Suraj Subramanian](https://github.com/subramen), [Seth\n",
        "Juarez](https://github.com/sethjuarez/), [Cassie\n",
        "Breviu](https://github.com/cassiebreviu/), [Dmitry\n",
        "Soshnikov](https://soshnikov.com/), [Ari\n",
        "Bornstein](https://github.com/aribornstein/)\n",
        "\n",
        "Most machine learning workflows involve working with data, creating\n",
        "models, optimizing model parameters, and saving the trained models. This\n",
        "tutorial introduces you to a complete ML workflow implemented in\n",
        "PyTorch, with links to learn more about each of these concepts.\n",
        "\n",
        "We\\'ll use the FashionMNIST dataset to train a neural network that\n",
        "predicts if an input image belongs to one of the following classes:\n",
        "T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker,\n",
        "Bag, or Ankle boot.\n",
        "\n",
        "[This tutorial assumes a basic familiarity with Python and Deep Learning\n",
        "concepts.]{.title-ref}\n",
        "\n",
        "Running the Tutorial Code\n",
        "-------------------------\n",
        "\n",
        "You can run this tutorial in a couple of ways:\n",
        "\n",
        "-   **In the cloud**: This is the easiest way to get started! Each\n",
        "    section has a \\\"Run in Microsoft Learn\\\" and \\\"Run in Google Colab\\\"\n",
        "    link at the top, which opens an integrated notebook in Microsoft\n",
        "    Learn or Google Colab, respectively, with the code in a fully-hosted\n",
        "    environment.\n",
        "-   **Locally**: This option requires you to setup PyTorch and\n",
        "    TorchVision first on your local machine ([installation\n",
        "    instructions](https://pytorch.org/get-started/locally/)). Download\n",
        "    the notebook or copy the code into your favorite IDE.\n",
        "\n",
        "How to Use this Guide\n",
        "---------------------\n",
        "\n",
        "If you\\'re familiar with other deep learning frameworks, check out the\n",
        "[0. Quickstart](quickstart_tutorial.html) first to quickly familiarize\n",
        "yourself with PyTorch\\'s API.\n",
        "\n",
        "If you\\'re new to deep learning frameworks, head right into the first\n",
        "section of our step-by-step guide: [1. Tensors](tensorqs_tutorial.html).\n",
        "\n",
        "::: {.toctree maxdepth=\"2\" hidden=\"\"}\n",
        "quickstart\\_tutorial tensorqs\\_tutorial data\\_tutorial\n",
        "transforms\\_tutorial buildmodel\\_tutorial autogradqs\\_tutorial\n",
        "optimization\\_tutorial saveloadrun\\_tutorial\n",
        ":::\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CttytIjaUXP8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensors"
      ],
      "metadata": {
        "id": "DFfNTZ7tUyjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "OUV6jk5jU4t2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing directly from data\n",
        "data = [[1,2], [3,4]]\n",
        "x_data = torch.tensor(data)"
      ],
      "metadata": {
        "id": "bYakFcW-VCPt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing from a numpy array\n",
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ],
      "metadata": {
        "id": "ouzLop2EVO6m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing from another tensor\n",
        "x_ones = torch.ones_like(x_data) # retains the property of x_data\n",
        "print(f\"Ones Tensor: \\n{x_ones}\\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype = torch.float) #overrides the datatype of x_data\n",
        "print(f\"Random Tensor\\n{x_rand}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXn-4i25VZKF",
        "outputId": "8861c061-87e3-4f7e-ffeb-d2a1bf084cec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            "tensor([[1, 1],\n",
            "        [1, 1]])\n",
            "\n",
            "Random Tensor\n",
            "tensor([[0.5624, 0.9134],\n",
            "        [0.4094, 0.3858]])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing with random or constant values\n",
        "\n",
        "shape = (2,3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Randome Tensor: \\n{rand_tensor}\\n\")\n",
        "print(f\"Ones Tensor: \\n{ones_tensor}\\n\")\n",
        "print(f\"Zeros Tensor: \\n{zeros_tensor}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcB_OgelV7UE",
        "outputId": "ad21cf97-e1c7-46b4-fc9b-ae5dcfce85ac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Randome Tensor: \n",
            "tensor([[0.8992, 0.3337, 0.8256],\n",
            "        [0.6420, 0.0016, 0.8631]])\n",
            "\n",
            "Ones Tensor: \n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "\n",
            "Zeros Tensor: \n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attributes of a Tensor\n",
        "tensor = torch.rand(3,4)\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5ESdcSVWWis",
        "outputId": "47dc530f-c4a0-46dc-c772-52bbe8b514d9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Operations on Tensors\n",
        "\n",
        "if torch.accelerator.is_available():\n",
        "  tensor = tensor.to(torch.accelerator.current_accelerator())\n"
      ],
      "metadata": {
        "id": "igm_gGRNWirs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard numpy-like indexing and slicing:\n",
        "tensor = torch.ones(4,4)\n",
        "print(f\"First row: {tensor[0]}\")\n",
        "print(f\"First column {tensor[:,0]}\")\n",
        "print(f\"Last column {tensor[...,-1]}\")\n",
        "tensor[:,1]=0\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxzHS2y0Zhsu",
        "outputId": "7f87846f-43d1-40fb-ee76-5c2f39a2c719"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row: tensor([1., 1., 1., 1.])\n",
            "First column tensor([1., 1., 1., 1.])\n",
            "Last column tensor([1., 1., 1., 1.])\n",
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Joining tensors: torch.cat to concatenate a sequence of tensors, also torch.stack\n",
        "t1 = torch.cat([tensor, tensor, tensor], dim = 1)\n",
        "print(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PG4QIjL4Z50I",
        "outputId": "1dfd094c-6cfb-4f69-d117-1c6ccd99e678"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Arithmetic operations\n",
        "# `` tensor.T`` returns the transpose of a tensor\n",
        "\n",
        "y1 = tensor @ tensor.T\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "y3 = torch.rand_like(y1)\n",
        "print(tensor, tensor.T)\n",
        "print(y1,y2)\n",
        "torch.matmul(tensor, tensor.T, out = y3)\n",
        "print(y3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9Tgl7VBdKIi",
        "outputId": "28c7d94c-a788-49dd-f534-3c2d4e830bdd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) tensor([[1., 1., 1., 1.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]]) tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]])\n",
            "tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# single-element tensors\n",
        "agg = tensor.sum()\n",
        "agg_item = agg.item()\n",
        "print(agg_item, type(agg_item))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqBM0sddd3Te",
        "outputId": "d78d6178-5c12-4b73-cfb2-0780427f6862"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12.0 <class 'float'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVbecTpM_j5e",
        "outputId": "c69deffb-ca28-42d0-c727-ddfa0f4d7a20"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In-place operation, store the result into the operand, denoted by a _ suffix. like x.copy_(y), x.t_() will change x.\n",
        "print(f\"{tensor}\")\n",
        "tensor.add_(5)\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXiO9qUb_6he",
        "outputId": "15dc60cb-6aef-41d0-b9af-c98f62419b07"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n",
            "tensor([[6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bridge with Numpy: tensors on the cpu and numpy arrays can share their underlying memory locations, change one will change the other.\n",
        "# Tensor to Numpy array\n",
        "t = torch.ones(5)\n",
        "print(f\"t:{t}\")\n",
        "n = t.numpy()\n",
        "print(f\"n:{n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mba7Plj1AZCo",
        "outputId": "39f03549-d0f9-49c3-8969-4432c431c644"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t:tensor([1., 1., 1., 1., 1.])\n",
            "n:[1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a change in the tensor reflects in the numpy array\n",
        "t.add_(1)\n",
        "print(f\"t:{t}\")\n",
        "print(f\"n:{n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Td8g0wFAzS4",
        "outputId": "f2183eaa-639d-4bb7-80ff-b007a7f52858"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t:tensor([2., 2., 2., 2., 2.])\n",
            "n:[2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy array to tensor, changes in the numpy array reflects in the tensor\n",
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)\n",
        "np.add(n, 1, out = n)\n",
        "print(f\"t:{t}\")\n",
        "print(f\"n:{n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upSzdq58A80B",
        "outputId": "6a9fe4c0-bade-4c15-c3e0-c30696efd1c3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t:tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "n:[2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets & DataLoaders"
      ],
      "metadata": {
        "id": "g-TnXWy5BdPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Target to decouple the dataset code and model training code for better readability and modularity.\n",
        "# torch.utils.data.DataLoader and torch.utils.data.Dataset: to use pre-loaded datasets and your own data,\n",
        "# Dataset stores the samples and their corresponding labels, DataLoader wraps an iterable around the Dataset\n",
        "# to enable easy access to the samples"
      ],
      "metadata": {
        "id": "RpyXSCbjBKtB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading a Dataset\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    train = False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "n8M-fxewCL79"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterating and visualizing the Dataset: we can index Datasets like training_data[index]\n",
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "figure = plt.figure(figsize=(6,6))\n",
        "cols, rows = 3,3\n",
        "for i in range(1, cols*rows+1):\n",
        "  sample_idx = torch.randint(len(training_data), size = (1,)).item()\n",
        "  img, label = training_data[sample_idx]\n",
        "  figure.add_subplot(rows, cols, i)\n",
        "  plt.title(labels_map[label])\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(img.squeeze(), cmap = \"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "F-OKqSvvDU8v",
        "outputId": "75886432-6ea8-466a-e59d-8ff4aaddd571"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Creating a Custom Dataset for your files\n",
        "A custom dataset class must implement three functions: __init__, __len__, and __getitem__.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FhnNjdCeEW0i",
        "outputId": "d44d73bb-8cb2-4311-df71-45f625a2ded2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nCreating a Custom Dataset for your files\\nA custom dataset class must implement three functions: __init__, __len__, and __getitem__. \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Preparing your data for training with DataLoaders.\n",
        "Dataset will retrieves dataset's feature and label one sample at a time.\n",
        "But to pass samples in minibatches, and reshuffle the data at every epoch to reduce model overfitting,\n",
        "by using python's multiprocessing to speed up data retrieval.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SZEkHO0PMogH",
        "outputId": "7f28e3ae-c270-4b93-eb7c-61cc469c495a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nPreparing your data for training with DataLoaders.\\nDataset will retrieves dataset's feature and label one sample at a time. \\nBut to pass samples in minibatches, and reshuffle the data at every epoch to reduce model overfitting, \\nby using python's multiprocessing to speed up data retrieval.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_dataloader = DataLoader(training_data, batch_size = 64, shuffle = True)\n",
        "test_dataloader = DataLoader(test_data, batch_size = 64, shuffle = True)\n"
      ],
      "metadata": {
        "id": "GqO8Wc7dk19t"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through the DataLoader\n",
        "# Each iteration below returns a batch of train_features and train_labels, which contains batch_size features\n",
        "# and labels respectively.\n",
        "\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Feature batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "j9EBftCjmliP",
        "outputId": "f8cc0218-0864-4869-f75e-366576de5eb2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
            "Feature batch shape: torch.Size([64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_s3xUkGCuxz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transforms"
      ],
      "metadata": {
        "id": "9YJL013yu-RR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use transform to perform some manipulation of the data and make it suitable for training.\n",
        "# All torchVision datasets have two parameters - transform to modify the features and target_transform to modify the labels.\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "\n",
        "ds = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
        ")\n"
      ],
      "metadata": {
        "id": "6DUQaoW9vAjE"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "ToTensor()\n",
        " Convert a PIL image or numpy ndarray into a FloatTensor, and scales the image's pixel intensity values in the range [0.,1.]\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8GmflU8IyXfi",
        "outputId": "7561b364-6eb0-4e42-9bed-dc69bcedfee1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nToTensor()\\n Convert a PIL image or numpy ndarray into a FloatTensor, and scales the image's pixel intensity values in the range [0.,1.]\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lambda Transforms\n",
        "\"Lambda transforms apply any user-defined lambda function\"\n",
        "target_transform = Lambda(lambda y: torch.zeros(10, dtype = torch.float).scatter_(dim=0, index = torch.tensor(y), value=1))\n",
        "print(target_transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzKbSzL7yzjs",
        "outputId": "fe89af47-12c9-4774-8357-1e076d3a6128"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lambda()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cs7kJCr4zaSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the Neural Network"
      ],
      "metadata": {
        "id": "l9iX985Jzv4a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural networks comprise of layers/modules that perform operations on data.\n",
        "\n",
        "torch.nn provides all the building blocks you need to build your own neural network. Every module in pytorch subclasses the nn.Module. A neural network is a module itself that consists of other modules(layers). this nested structure allows for building and managing complex architectures easily."
      ],
      "metadata": {
        "id": "xQgHALwz0haE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "xI5skxnJzzL9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get device for Training\n",
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9Ct4EXR1PXr",
        "outputId": "d2c34629-f814-479a-ea72-acb4f5276f5d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Class: by subclassing nn.Module, initialize the neural network layer in __init__.\n",
        "# Every nn.Module subclass implements the operations on input data in the forward method.\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        ""
      ],
      "metadata": {
        "id": "_qHMb7f_1hXx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdlqiE9J4SS-",
        "outputId": "c51480b2-1bc8-44bd-d27e-1beea3ae0704"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To use the model. we pass it the input data. this executes the model's forward,\n",
        "# along with some background operations. do not call model.forward() directly.\n",
        "\"\"\" Calling the model on the input returns a 22-dimensional tensor with dim=0 corresponding to each output\n",
        "of 10 raw predicted values for each class, and dim = 1 corresponding to the individual values of each output.\n",
        "we get the prediction probabilities by passing it through an instance of the nn.Softmax module.\"\"\"\n",
        "X = torch.rand(1,28,28, device = device)\n",
        "logits = model(X)\n",
        "print(logits)\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IInf0PhV4cbW",
        "outputId": "dcb7d9d1-4e53-4133-f8ff-8e3cdc6228ae"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0485,  0.0229, -0.0638, -0.0505,  0.1250, -0.0593, -0.0147,  0.0962,\n",
            "          0.1547,  0.0942]], grad_fn=<AddmmBackward0>)\n",
            "Predicted class: tensor([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Layers\n",
        "input_image = torch.rand(3,28,28)\n",
        "print(input_image.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCsYGxHK5g5K",
        "outputId": "b3242dd0-bf50-4aa8-d209-3f67a1b3bea8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.Flatten: example to convert a 2D 28*28 image into a contiguous array of 784 pixel values\n",
        "flatten = nn.Flatten()\n",
        "flat_image = flatten(input_image)\n",
        "print(flat_image.size())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH6QEs5L6luz",
        "outputId": "421e9cfb-9b50-468a-8f7b-11dc01f46028"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.Linear: applies a linear transformation on the input using its stored weights and biases\n",
        "layer1 = nn.Linear(in_features = 28*28, out_features=20)\n",
        "hidden1 = layer1(flat_image)\n",
        "print(hidden1.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p33aww47WM8",
        "outputId": "33e4142f-e456-4fad-f2e7-ebdf2fcb8e83"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.ReLU: Non-linear activations are what create the complex mappings between the model's inputs and outputs.\n",
        "# applied after linear transformation to introduce nonlinearity, helping nn learn a wide varity of phenomena.\n",
        "print(f\"Before ReLU: {hidden1}, {hidden1.size()}\")\n",
        "\n",
        "hidden1 = nn.ReLU()(hidden1)\n",
        "print(f\"After ReLU: {hidden1}, {hidden1.size()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wKMqEcN7uMG",
        "outputId": "c905bdc4-de25-47ea-cd94-981196f36af0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before ReLU: tensor([[0.0519, 0.0000, 0.1881, 0.0000, 0.5788, 0.0000, 0.3735, 0.2277, 0.0000,\n",
            "         0.0323, 0.0000, 0.0000, 0.0254, 0.6520, 0.0086, 0.1952, 0.0000, 0.4234,\n",
            "         0.2610, 0.2590],\n",
            "        [0.0058, 0.0000, 0.4677, 0.0000, 0.1608, 0.0000, 0.1261, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.3663, 0.2406, 0.3188, 0.0000, 0.4090,\n",
            "         0.4362, 0.2828],\n",
            "        [0.0000, 0.0000, 0.4049, 0.0849, 0.4178, 0.0000, 0.1921, 0.0806, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.2279, 0.0000, 0.3913, 0.0000, 0.1732,\n",
            "         0.0244, 0.3129]], grad_fn=<ReluBackward0>), torch.Size([3, 20])\n",
            "After ReLU: tensor([[0.0519, 0.0000, 0.1881, 0.0000, 0.5788, 0.0000, 0.3735, 0.2277, 0.0000,\n",
            "         0.0323, 0.0000, 0.0000, 0.0254, 0.6520, 0.0086, 0.1952, 0.0000, 0.4234,\n",
            "         0.2610, 0.2590],\n",
            "        [0.0058, 0.0000, 0.4677, 0.0000, 0.1608, 0.0000, 0.1261, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.3663, 0.2406, 0.3188, 0.0000, 0.4090,\n",
            "         0.4362, 0.2828],\n",
            "        [0.0000, 0.0000, 0.4049, 0.0849, 0.4178, 0.0000, 0.1921, 0.0806, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.2279, 0.0000, 0.3913, 0.0000, 0.1732,\n",
            "         0.0244, 0.3129]], grad_fn=<ReluBackward0>), torch.Size([3, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#nn.Sequential: is an ordered container of modules, data is passed through all the modules in the same order\n",
        "#as defined, we can use sequential container to put together a quick network like seq_modules\n",
        "seq_modules = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(in_features = 28*28, out_features=20),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 10)\n",
        ")\n",
        "\n",
        "input_image = torch.rand(3,28,28)\n",
        "logits = seq_modules(input_image)\n",
        "print(logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyt1-j3g8YZw",
        "outputId": "6cf34927-02f5-4394-92a0-3d901873e2dd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0076,  0.1658,  0.1552, -0.0835, -0.0983, -0.2042, -0.0103,  0.1209,\n",
            "         -0.0239,  0.2084],\n",
            "        [-0.1794,  0.2357,  0.3217, -0.0959, -0.1305, -0.0709, -0.1747, -0.0491,\n",
            "          0.0211,  0.2486],\n",
            "        [-0.0306,  0.1775,  0.1982, -0.0815, -0.1139, -0.1585, -0.0164,  0.0892,\n",
            "         -0.1069,  0.1777]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.Softmax: the last linear layer of the nn returns logits - raw values in [-infty, infty]. the logits\n",
        "# are scaled to value [0,1] representing the model's predicted probabilities for each class.\n",
        "# dim indicates the dimension along which the values must sum to 1\n",
        "\n",
        "softmax = nn.Softmax(dim=1)\n",
        "pred_probab = softmax(logits)\n",
        "print(pred_probab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVPRTW7u9tIy",
        "outputId": "4058a8f0-0e3d-4b27-d18e-84e7b8314e4e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0963, 0.1145, 0.1133, 0.0892, 0.0879, 0.0791, 0.0960, 0.1095, 0.0947,\n",
            "         0.1195],\n",
            "        [0.0812, 0.1230, 0.1340, 0.0883, 0.0853, 0.0905, 0.0816, 0.0925, 0.0992,\n",
            "         0.1246],\n",
            "        [0.0949, 0.1168, 0.1193, 0.0902, 0.0873, 0.0835, 0.0962, 0.1070, 0.0879,\n",
            "         0.1169]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Parameters, weights and biases that are optmized during training, nn.Module automatically tracks\n",
        "# all fields defined inside the model object, all parameters accessible using parameters() or named_parameters()\n",
        "print(f\"Model structure: {model}\")\n",
        "for name, param in model.named_parameters():\n",
        "  print(f\"Layer: {name} | Size: {param.size()} | Values: {param[:2]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfUeC3_5-hWD",
        "outputId": "61ec87b8-4aea-4fee-a686-16191a00a88f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure: NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values: tensor([[ 0.0058,  0.0059,  0.0259,  ..., -0.0035, -0.0102, -0.0234],\n",
            "        [-0.0168,  0.0322, -0.0006,  ...,  0.0120,  0.0199, -0.0164]],\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values: tensor([-0.0334,  0.0191], grad_fn=<SliceBackward0>)\n",
            "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values: tensor([[-0.0119,  0.0031,  0.0242,  ...,  0.0351,  0.0374,  0.0317],\n",
            "        [-0.0171, -0.0202,  0.0033,  ...,  0.0329,  0.0370, -0.0020]],\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values: tensor([ 0.0063, -0.0425], grad_fn=<SliceBackward0>)\n",
            "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values: tensor([[ 0.0325,  0.0064, -0.0165,  ..., -0.0043, -0.0117, -0.0248],\n",
            "        [-0.0111, -0.0231,  0.0211,  ...,  0.0386, -0.0235,  0.0322]],\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values: tensor([-0.0210, -0.0009], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Automatic Differentiation with torch.autograd"
      ],
      "metadata": {
        "id": "go7Wz93IAIpr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When training neural networks, the most frequently used algo is back propogation. in this algo, parameters(model weights) are adjusted according to the gradient of the loss function with respect to the given parameter.\n",
        "\n",
        "Pytorch use a built-in differentiation engine torch.autograd to compute gradients for any computational graph."
      ],
      "metadata": {
        "id": "VmTtViNjARTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x = torch.ones(5) # input tensor\n",
        "y = torch.zeros(3) # expected output\n",
        "w = torch.randn(5,3, requires_grad = True)\n",
        "b = torch.randn(3, requires_grad = True)\n",
        "z = torch.matmul(x, w)+b\n",
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z,y)\n",
        "print(f\"Gradient function for z = {z.grad_fn}\")\n",
        "print(f\"Gradient function for loss = {loss.grad_fn}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUZ8CQUKZ_QA",
        "outputId": "b8aa8853-fbef-48fc-d69d-b0b2a15a1f05"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient function for z = <AddBackward0 object at 0x7b227aebbbe0>\n",
            "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x7b227b2adc60>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing Gradients\n",
        "\n",
        "To optimize weights of parameters in the neural network, we need to compute the derivatives of our loss function with respect to parameters, to compute derivatives, we call loss.backward() and then retrieve the values from w.grad and b.grad.\n",
        "\n",
        "We can only obtain the grad properties for the leaf nodes of the computational graph, which have requirs_grad property set to True.\n",
        "\n",
        "We can only perform gradient calculations using backward **once** on a given graph, need to pass retain_graph = True to the backward call if need to do several backward calls on the same graph."
      ],
      "metadata": {
        "id": "yudNoE4Ea02W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward(retain_graph=True)\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf3gW1o8bTZh",
        "outputId": "3c0c2ecc-f069-4f5b-9d22-befb40e6c56d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1394, 0.3008, 0.6490],\n",
            "        [0.1394, 0.3008, 0.6490],\n",
            "        [0.1394, 0.3008, 0.6490],\n",
            "        [0.1394, 0.3008, 0.6490],\n",
            "        [0.1394, 0.3008, 0.6490]])\n",
            "tensor([0.1394, 0.3008, 0.6490])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Disabling Gradient Tracking\n",
        "\n",
        "All tensors with requires_grad = True are tracking their computational history and support gradient computation. if we don't want to do that like just want to apply a trained model to some input data. we only want to do forward computations through the network. We can stop tracking computations by surrounding our computations code with **torch.no_grad()** block."
      ],
      "metadata": {
        "id": "mDW0hlrobpP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.matmul(x,w)+b\n",
        "print(z.requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    z = torch.matmul(x,w)+b\n",
        "print(z.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH4giDEubfUI",
        "outputId": "3225c68c-80b6-4c05-962b-bbf571ecc204"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another way to achieve same effect as torch.no_grad() is to use the detach() method on the tensor."
      ],
      "metadata": {
        "id": "znpGLwgjeiFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.matmul(x,w)+b\n",
        "z_det = z.detach()\n",
        "print(z_det.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwbzKuikefQD",
        "outputId": "b0030280-6a87-4567-fea3-5c2ab942a4c6"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When need to disable gradient tracking:\n",
        "1. to make some parameters in your neural network as frozen parameters\n",
        "2. To speed up computtions when you are only doing forward pass, because computations on tensors that do not track gradients would be more efficient."
      ],
      "metadata": {
        "id": "SoKlLAtmfPE5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MISSING\n",
        "Optional Reading: Tensor Gradients and Jacobian Products"
      ],
      "metadata": {
        "id": "tmuTk5d9hmLD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizing Model Parameters"
      ],
      "metadata": {
        "id": "Ybrl3sCYhy1N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training a model is an iterative process, in each iteration the model make a guess about the output, calculate the error in its guess(loss), collects the derivatives of the error with respect to its parameters, and optimize these parameters using gradient descent."
      ],
      "metadata": {
        "id": "_hl765bGj6se"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prerequisite Code\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = ToTensor()\n",
        ")\n",
        "train_dataloader = DataLoader(training_data, batch_size = 64)\n",
        "test_dataloader = DataLoader(test_data, batch_size = 64)\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "          nn.Linear(28*28, 512),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(512, 512),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(512, 10)\n",
        "       )\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "model = NeuralNetwork()"
      ],
      "metadata": {
        "id": "rjHrU-jChxp-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "\"\"\"Hyperparameters are adjustable parameters that let you control the model optimization process.\n",
        "Different hyperparameter values can impact model training and convergence rates. Hyperparameters:\n",
        "1) Number of Epochs: the number of times to iterate over the dataset\n",
        "2) Batch Size: the number of data samples propagated through the network before the parameters are updated.\n",
        "3) Learning Rate: how much to update models parameters at each batch/epoch.\n",
        "\"\"\"\n",
        "\n",
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "CsDhbyyXvuj5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization Loop\n",
        "\n",
        "Each iteration of the optimization loop is called an epoch, Each epoch consists of two main parts:\n",
        "1) The Train Loop: iterate over the training dataset and try to converge to optimal parameters\n",
        "2) The Validation/Test Loop: iterate over the test dataset to check if model performance is improving."
      ],
      "metadata": {
        "id": "v51yElKq09L0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss Function\n",
        "When presented with some training data, our untrained network is likely not to give the correct answer. Loss\n",
        "Function measures the degree of dissimilarity of obtained result to the target value, and it is the loss function that we want to minimize during training. To calculate the loss we make a prediction using the iputs of our given data sample and compare it against the true data label value. Loss Function:\n",
        "1) nn.MSELoss(Mean Square Error): for regression tasks\n",
        "2) nn.NLLLoss(Negative Log Likelihood): for classification.\n",
        "3) nn.CrossEntropyLoss: combines nn.LogSoftmax and nn.NLLLoss.\n"
      ],
      "metadata": {
        "id": "EccYctD-21GM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the loss function.\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "EiVUUtUy00WM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer**\n",
        "\n",
        "Optimization is the process of adjusting model parameters to reduce model error in each training step. Optimization algorithms define how this process is performed. All optimization logic is encapsulated in the optimizer object.\n",
        "\n",
        "We initialize the optimizer by registering the model's parameters that need to be trained, and passing in the learning rate hyperparameter."
      ],
      "metadata": {
        "id": "AIlIeXsG4zSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "TTID5ow94wJH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inside the training loop, optimization happens in three steps:\n",
        "1) Call optimizer.zero_grad() to reset the gradients of model parameters. Gradients by default add up; to prevent double-counting, we explicitly zero them at each iteraion.\n",
        "2) Backpropagate the prediction loss with a call to loss.backward().\n",
        "3) Once we have gradients, we call optimizer.step() to adjust the parameters by the gradients collected in the backward pass."
      ],
      "metadata": {
        "id": "R3OLfiul6ZUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Full Implementation\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    # set the model to training mode - important for batch normalization and dropout layers\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch*batch_size+len(X)\n",
        "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensure that no gradients are computed during test mode\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /=size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "0M9ppwqe5dZH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVvgH4NB_bZb",
        "outputId": "b4c506a5-1250-43ab-990b-a9da570d6a76"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.301873 [   64/60000]\n",
            "loss: 2.290184 [ 6464/60000]\n",
            "loss: 2.278075 [12864/60000]\n",
            "loss: 2.268346 [19264/60000]\n",
            "loss: 2.239050 [25664/60000]\n",
            "loss: 2.218196 [32064/60000]\n",
            "loss: 2.218289 [38464/60000]\n",
            "loss: 2.192700 [44864/60000]\n",
            "loss: 2.190942 [51264/60000]\n",
            "loss: 2.147700 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 47.4%, Avg loss: 0.013944 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.167764 [   64/60000]\n",
            "loss: 2.155818 [ 6464/60000]\n",
            "loss: 2.104565 [12864/60000]\n",
            "loss: 2.112669 [19264/60000]\n",
            "loss: 2.050687 [25664/60000]\n",
            "loss: 1.999017 [32064/60000]\n",
            "loss: 2.015418 [38464/60000]\n",
            "loss: 1.945928 [44864/60000]\n",
            "loss: 1.942126 [51264/60000]\n",
            "loss: 1.865056 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 59.3%, Avg loss: 0.012234 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.906806 [   64/60000]\n",
            "loss: 1.879015 [ 6464/60000]\n",
            "loss: 1.760952 [12864/60000]\n",
            "loss: 1.792804 [19264/60000]\n",
            "loss: 1.675062 [25664/60000]\n",
            "loss: 1.636010 [32064/60000]\n",
            "loss: 1.641592 [38464/60000]\n",
            "loss: 1.557377 [44864/60000]\n",
            "loss: 1.570202 [51264/60000]\n",
            "loss: 1.462889 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 61.3%, Avg loss: 0.009733 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.557918 [   64/60000]\n",
            "loss: 1.530552 [ 6464/60000]\n",
            "loss: 1.375166 [12864/60000]\n",
            "loss: 1.447223 [19264/60000]\n",
            "loss: 1.317122 [25664/60000]\n",
            "loss: 1.324141 [32064/60000]\n",
            "loss: 1.327534 [38464/60000]\n",
            "loss: 1.268235 [44864/60000]\n",
            "loss: 1.296006 [51264/60000]\n",
            "loss: 1.196627 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 63.1%, Avg loss: 0.007887 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.305344 [   64/60000]\n",
            "loss: 1.296321 [ 6464/60000]\n",
            "loss: 1.121288 [12864/60000]\n",
            "loss: 1.234482 [19264/60000]\n",
            "loss: 1.099032 [25664/60000]\n",
            "loss: 1.129717 [32064/60000]\n",
            "loss: 1.144137 [38464/60000]\n",
            "loss: 1.096883 [44864/60000]\n",
            "loss: 1.130895 [51264/60000]\n",
            "loss: 1.047485 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.6%, Avg loss: 0.006671 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.142857 [   64/60000]\n",
            "loss: 1.154624 [ 6464/60000]\n",
            "loss: 0.960295 [12864/60000]\n",
            "loss: 1.105881 [19264/60000]\n",
            "loss: 0.972810 [25664/60000]\n",
            "loss: 1.002832 [32064/60000]\n",
            "loss: 1.034469 [38464/60000]\n",
            "loss: 0.990104 [44864/60000]\n",
            "loss: 1.024416 [51264/60000]\n",
            "loss: 0.956394 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 66.0%, Avg loss: 0.005823 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.030722 [   64/60000]\n",
            "loss: 1.064054 [ 6464/60000]\n",
            "loss: 0.850574 [12864/60000]\n",
            "loss: 1.020689 [19264/60000]\n",
            "loss: 0.894302 [25664/60000]\n",
            "loss: 0.913349 [32064/60000]\n",
            "loss: 0.962679 [38464/60000]\n",
            "loss: 0.919905 [44864/60000]\n",
            "loss: 0.950047 [51264/60000]\n",
            "loss: 0.894186 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 67.1%, Avg loss: 0.005186 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.946963 [   64/60000]\n",
            "loss: 0.999749 [ 6464/60000]\n",
            "loss: 0.770669 [12864/60000]\n",
            "loss: 0.959315 [19264/60000]\n",
            "loss: 0.840995 [25664/60000]\n",
            "loss: 0.847456 [32064/60000]\n",
            "loss: 0.910998 [38464/60000]\n",
            "loss: 0.871532 [44864/60000]\n",
            "loss: 0.895355 [51264/60000]\n",
            "loss: 0.848361 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 68.2%, Avg loss: 0.004683 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.881116 [   64/60000]\n",
            "loss: 0.950128 [ 6464/60000]\n",
            "loss: 0.709794 [12864/60000]\n",
            "loss: 0.912567 [19264/60000]\n",
            "loss: 0.801791 [25664/60000]\n",
            "loss: 0.797455 [32064/60000]\n",
            "loss: 0.870977 [38464/60000]\n",
            "loss: 0.836886 [44864/60000]\n",
            "loss: 0.853540 [51264/60000]\n",
            "loss: 0.812501 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 69.6%, Avg loss: 0.004271 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.827410 [   64/60000]\n",
            "loss: 0.909465 [ 6464/60000]\n",
            "loss: 0.661702 [12864/60000]\n",
            "loss: 0.875577 [19264/60000]\n",
            "loss: 0.771338 [25664/60000]\n",
            "loss: 0.758779 [32064/60000]\n",
            "loss: 0.838068 [38464/60000]\n",
            "loss: 0.810792 [44864/60000]\n",
            "loss: 0.820560 [51264/60000]\n",
            "loss: 0.783211 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 71.0%, Avg loss: 0.003925 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save & Load Model"
      ],
      "metadata": {
        "id": "3qORxUkwBWPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n"
      ],
      "metadata": {
        "id": "0xwvyfZ9_3dK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving and Loading Model Weights\n",
        "# Pytorch models store the learned parameters in an internal state dictionary,\n",
        "# called state_dict, which can be persisted via torch.save\n",
        "model = models.vgg16(weights = \"IMAGENET1K_V1\")\n",
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11Nqn1ZnBqOW",
        "outputId": "b357d236-938f-4a8f-9684-88b97f5707e8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 528M/528M [00:07<00:00, 70.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To load model weights, need to create an instance of the same model first,\n",
        "# then load the parameters using load_state_dict(), set weights_only = True to limit the functions\n",
        "# executed during unpickling to only those necessary for loading weights\n",
        "\n",
        "model = models.vgg16()\n",
        "model.load_state_dict(torch.load('model_weights.pth', weights_only=True))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh3HeFSCB72k",
        "outputId": "904ad9a6-3c7c-4b17-f99a-2f7e8c1fd5a2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving and loading models with Shapes\n",
        "torch.save(model, 'model.pth')"
      ],
      "metadata": {
        "id": "DlnR4Up6Cb4H"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('model.pth', weights_only=False)"
      ],
      "metadata": {
        "id": "NIk4N4LDDSvH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6grKcKLgDX1N"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}